{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ac4f5",
   "metadata": {},
   "source": [
    "## Code to simulate smt like guitar output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdec8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "\n",
    "def make_test_params(\n",
    "    batch_size=1,\n",
    "    num_frames=400,          # longer sequence for a melody (~4 sec if frame_rate=100)\n",
    "    num_harmonics=64,\n",
    "    num_noise_bands=32,\n",
    "    num_filter_coeffs=8,\n",
    "    sr=16000,\n",
    "    frame_rate=100,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulate parameters for a simple plucked-guitar melody.\n",
    "    \"\"\"\n",
    "\n",
    "    B, T = batch_size, num_frames\n",
    "    t = torch.linspace(0, T / frame_rate, T, device=device)  # seconds\n",
    "\n",
    "    # --- Melody: sequence of discrete notes (A, C, E, G, etc.) ---\n",
    "    # F0 sequence of simple melody in Hz\n",
    "    notes_hz = [110.0, 146.8, 196.0, 220.0, 246.9, 196.0, 164.8, 146.8]  # A2–B3 range\n",
    "    note_dur = T // len(notes_hz)\n",
    "    f0 = torch.zeros(B, T, device=device)\n",
    "    for i, f in enumerate(notes_hz):\n",
    "        start = i * note_dur\n",
    "        end = (i + 1) * note_dur\n",
    "        f0[:, start:end] = f + 3.0 * torch.sin(2 * math.pi * 5 * t[start:end])  # small vibrato\n",
    "\n",
    "    # --- Harmonic amplitudes ---\n",
    "    # Exponential decay + stronger odd harmonics (typical of guitar)\n",
    "    decay = torch.exp(-0.07 * torch.arange(num_harmonics, device=device))\n",
    "    odd_mask = ((torch.arange(num_harmonics, device=device) + 1) % 2).float()\n",
    "    harmonic_pattern = 0.6 + 0.4 * odd_mask  # emphasize odd harmonics\n",
    "    harmonic_base = decay * harmonic_pattern\n",
    "    harmonic_amps = (torch.rand(B, T, num_harmonics, device=device) * 0.2 + 0.8) * harmonic_base\n",
    "\n",
    "    # --- Gain envelope: per-note pluck ---\n",
    "    gain = torch.zeros(B, T, 1, device=device)\n",
    "    for i in range(len(notes_hz)):\n",
    "        start = i * note_dur\n",
    "        end = min((i + 1) * note_dur, T)\n",
    "        note_t = torch.linspace(0, 1, end - start, device=device)\n",
    "        env = torch.exp(-5 * note_t)  # fast decay\n",
    "        env[:3] = torch.linspace(0, 1, 3, device=device)  # quick attack\n",
    "        gain[:, start:end, 0] = env\n",
    "\n",
    "    # --- Transient envelope (very short burst at each pluck) ---\n",
    "    transient = gain * torch.exp(-40 * (t - (t * frame_rate % note_dur) / frame_rate).abs()).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "    # --- Noise (low level, smoothed) ---\n",
    "    noise_raw = 0.05 * torch.rand(B, T, num_noise_bands, device=device)\n",
    "    kernel_size = 5\n",
    "    sigma = 1.0\n",
    "    x = torch.arange(kernel_size, device=device) - (kernel_size - 1) / 2\n",
    "    kernel = torch.exp(-0.5 * (x / sigma) ** 2)\n",
    "    kernel = kernel / kernel.sum()\n",
    "    kernel = kernel.view(1, 1, kernel_size)\n",
    "    noise_smooth = []\n",
    "    for b in range(B):\n",
    "        bands = noise_raw[b].T.unsqueeze(0)\n",
    "        smooth = F.conv1d(bands, kernel.expand(num_noise_bands, 1, kernel_size), padding=kernel_size//2, groups=num_noise_bands)\n",
    "        noise_smooth.append(smooth.squeeze(0).T)\n",
    "    noise_amps = torch.stack(noise_smooth, dim=0)\n",
    "    noise_amps = torch.clamp(noise_amps, 0, 0.2)\n",
    "\n",
    "    # --- Filter coefficients (mild tone coloring) ---\n",
    "    filter_coeffs = torch.randn(B, T, num_filter_coeffs, device=device) * 0.03\n",
    "\n",
    "    params = {\n",
    "        \"harmonic_amps\": harmonic_amps,\n",
    "        \"noise_amps\": noise_amps,\n",
    "        \"gain\": gain,\n",
    "        \"optional\": {\n",
    "            \"filter_coeffs\": filter_coeffs,\n",
    "            \"transient\": transient\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return params, f0, sr, frame_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bb708",
   "metadata": {},
   "source": [
    "## Synthesize from parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c644259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def synthesize_from_params(params, f0, sr=16000, frame_rate=100):\n",
    "    \"\"\"\n",
    "    params: dict\n",
    "      harmonic_amps: (B, T, K_h)\n",
    "      noise_amps: (B, T, K_n)\n",
    "      gain: (B, T, 1)\n",
    "      optional: maybe filter_coeffs, transient (B, T, 1)\n",
    "    f0: (B, T) fundamental frequency in Hz\n",
    "    sr: sampling rate\n",
    "    frame_rate: how many frames per second (so T frames = T / frame_rate sec)\n",
    "    B – batch size\n",
    "    T – number of frames\n",
    "    K_h = number of harmonics\n",
    "    K_n = number of noise bands.\n",
    "    \"\"\"\n",
    "    B, T, K_h = params[\"harmonic_amps\"].shape\n",
    "    print(B, T, K_h)\n",
    "    _, _, K_n = params[\"noise_amps\"].shape\n",
    "    n_samples = int(T * sr / frame_rate)\n",
    "    device = params[\"harmonic_amps\"].device\n",
    "    \n",
    "    times = torch.linspace(0, T / frame_rate, n_samples, device=device, endpoint=False)\n",
    "    def interp_param(p):\n",
    "        B, T, X = p.shape\n",
    "        p2 = p.permute(0,2,1)\n",
    "        p2 = F.interpolate(p2, size=n_samples, mode='linear', align_corners=False)\n",
    "        p3 = p2.permute(0,2,1)\n",
    "        return p3\n",
    "    \n",
    "    harm_amp_s = interp_param(params[\"harmonic_amps\"])\n",
    "    noise_amp_s = interp_param(params[\"noise_amps\"]) \n",
    "    gain_s = interp_param(params[\"gain\"]).squeeze(-1)\n",
    "    f0_s = F.interpolate(f0.unsqueeze(-1).permute(0,2,1), size=n_samples, mode='linear').permute(0,2,1).squeeze(-1)\n",
    "    \n",
    "    if \"transient\" in params.get(\"optional\", {}):\n",
    "        transient_s = interp_param(params[\"optional\"][\"transient\"]).squeeze(-1)\n",
    "    else:\n",
    "        transient_s = None\n",
    "    \n",
    "    dt = 1.0 / sr\n",
    "    phase_f0 = torch.cumsum(f0_s * (2 * math.pi * dt), dim=1)\n",
    "    phases = phase_f0.unsqueeze(-1) * torch.arange(1, K_h+1, device=device).float()\n",
    "    sinusoids = torch.sin(phases)\n",
    "    y_harm = (harm_amp_s * sinusoids).sum(dim=-1)\n",
    "    \n",
    "    noise = torch.randn_like(y_harm)\n",
    "    if K_n == 1:\n",
    "        y_noise = noise * noise_amp_s.squeeze(-1)\n",
    "    else:\n",
    "\n",
    "        y_noise = noise * noise_amp_s.mean(dim=-1)\n",
    "    \n",
    "    y = y_harm + y_noise\n",
    "    if transient_s is not None:\n",
    "        y = y + transient_s\n",
    "    y = y * gain_s\n",
    "    \n",
    "    if \"filter_coeffs\" in params.get(\"optional\", {}):\n",
    "        pass\n",
    "    \n",
    "    y = torch.clamp(y, -1.0, 1.0)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a74af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 64\n",
      "torch.Size([1, 16000])\n"
     ]
    }
   ],
   "source": [
    "params, f0, sr, frame_rate = make_test_params(batch_size=1, num_frames=100)\n",
    "y = synthesize_from_params(params, f0, sr, frame_rate)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f7dde",
   "metadata": {},
   "source": [
    "## Saving audio to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721afaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Audio saved to test_synth.wav\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "waveform = y[0].detach().cpu().numpy()\n",
    "\n",
    "waveform = waveform / (abs(waveform).max() + 1e-6)\n",
    "sf.write(\"test_synth.wav\", waveform, sr)\n",
    "print(\"✅ Audio saved to test_synth.wav\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
